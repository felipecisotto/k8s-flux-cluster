apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: app-alerts
  namespace: monitoring
  labels:
    app.kubernetes.io/name: prometheus-operator
    app.kubernetes.io/part-of: kube-prometheus
spec:
  groups:
  - name: http.rules
    rules:
    # Alerta para latência elevada
    - alert: HTTPLatencyHigh
      expr: histogram_quantile(0.95, sum(rate(http_server_duration_milliseconds_bucket[5m])) by (job, http_route, le)) > 500
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: "Alta latência HTTP detectada"
        description: "A latência p95 para o serviço {{ $labels.job }} na rota {{ $labels.http_route }} está acima de 500ms nos últimos 5 minutos."
        dashboard_url: "https://grafana.felipecisotto.com.br/d/financial-backend-golden-signals/financial-backend-4-golden-signals?var-job={{ $labels.job }}&orgId=1&refresh=5s"

    # Alerta para latência muito elevada (crítica)
    - alert: HTTPLatencyCritical
      expr: histogram_quantile(0.95, sum(rate(http_server_duration_milliseconds_bucket[5m])) by (job, http_route, le)) > 1000
      for: 2m
      labels:
        severity: critical
      annotations:
        summary: "Latência HTTP crítica detectada"
        description: "A latência p95 para o serviço {{ $labels.job }} na rota {{ $labels.http_route }} está acima de 1000ms nos últimos 2 minutos."
        dashboard_url: "https://grafana.felipecisotto.com.br/d/financial-backend-golden-signals/financial-backend-4-golden-signals?var-job={{ $labels.job }}&orgId=1&refresh=5s"

    # Alerta para taxa de erros HTTP
    - alert: HTTPErrorRateHigh
      expr: sum(rate(http_server_duration_milliseconds_count{http_status_code=~"5.."}[5m])) by (job, http_route) / sum(rate(http_server_duration_milliseconds_count[5m])) by (job, http_route) > 0.05
      for: 2m
      labels:
        severity: warning
      annotations:
        summary: "Alta taxa de erros HTTP detectada"
        description: "A taxa de erros HTTP 5XX para o serviço {{ $labels.job }} na rota {{ $labels.http_route }} está acima de 5% nos últimos 2 minutos."
        dashboard_url: "https://grafana.felipecisotto.com.br/d/financial-backend-golden-signals/financial-backend-4-golden-signals?var-job={{ $labels.job }}&orgId=1&refresh=5s"

    # Alerta para taxa de erros HTTP crítica
    - alert: HTTPErrorRateCritical
      expr: sum(rate(http_server_duration_milliseconds_count{http_status_code=~"5.."}[5m])) by (job, http_route) / sum(rate(http_server_duration_milliseconds_count[5m])) by (job, http_route) > 0.10
      for: 1m
      labels:
        severity: critical
      annotations:
        summary: "Taxa de erros HTTP crítica detectada"
        description: "A taxa de erros HTTP 5XX para o serviço {{ $labels.job }} na rota {{ $labels.http_route }} está acima de 10% no último minuto."
        dashboard_url: "https://grafana.felipecisotto.com.br/d/financial-backend-golden-signals/financial-backend-4-golden-signals?var-job={{ $labels.job }}&orgId=1&refresh=5s"

  - name: app.rules
    rules:
    # Alerta para aumento de requisições
    - alert: HighRequestRate
      expr: sum(rate(http_server_duration_milliseconds_count[2m])) by (job, http_route) > 100
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: "Alta taxa de requisições"
        description: "O serviço {{ $labels.job }} na rota {{ $labels.http_route }} está recebendo mais de 100 requisições por segundo nos últimos 5 minutos."
        dashboard_url: "https://grafana.felipecisotto.com.br/d/financial-backend-golden-signals/financial-backend-4-golden-signals?var-job={{ $labels.job }}&orgId=1&refresh=5s"

---
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: proxmox-alerts
  namespace: monitoring
  labels:
    app.kubernetes.io/name: prometheus-operator
    app.kubernetes.io/part-of: kube-prometheus
spec:
  groups:
  - name: proxmox.host.rules
    rules:
    # Alerta para uso elevado de CPU no host Proxmox
    - alert: ProxmoxHostHighCPUUsage
      expr: (pve_cpu_usage_ratio{id="node/proxmox"} / pve_cpu_usage_limit{id="node/proxmox"}) * 100  > 80
      for: 10m
      labels:
        severity: warning
      annotations:
        summary: "Alto uso de CPU no host Proxmox"
        description: "O host Proxmox {{ $labels.instance }} está com uso de CPU acima de 80% ({{ $value | humanizePercentage }}) nos últimos 10 minutos."
        dashboard_url: "https://grafana.felipecisotto.com.br/d/Dp7Cd57Zza/proxmox-overview?orgId=1&refresh=10s"

    # Alerta para uso crítico de CPU no host Proxmox
    - alert: ProxmoxHostCriticalCPUUsage
      expr: (pve_cpu_usage_ratio{id="node/proxmox"} / pve_cpu_usage_limit{id="node/proxmox"}) * 100 > 95
      for: 5m
      labels:
        severity: critical
      annotations:
        summary: "Uso crítico de CPU no host Proxmox"
        description: "O host Proxmox {{ $labels.instance }} está com uso de CPU acima de 95% ({{ $value | humanizePercentage }}) nos últimos 5 minutos."
        dashboard_url: "https://grafana.felipecisotto.com.br/d/Dp7Cd57Zza/proxmox-overview?orgId=1&refresh=10s"


    # Alerta para uso crítico de memória no host Proxmox
    - alert: ProxmoxHostCriticalMemoryUsage
      expr: (pve_memory_usage_bytes{id="node/proxmox"} / pve_memory_size_bytes{id="node/proxmox"}) * 100 > 95
      for: 5m
      labels:
        severity: critical
      annotations:
        summary: "Uso crítico de memória no host Proxmox"
        description: "O host Proxmox {{ $labels.instance }} está com uso de memória acima de 95% ({{ $value | humanizePercentage }}) nos últimos 5 minutos."
        dashboard_url: "https://grafana.felipecisotto.com.br/d/Dp7Cd57Zza/proxmox-overview?orgId=1&refresh=10s"

    # Alerta para uso elevado de disco no host Proxmox
    - alert: ProxmoxHostHighDiskUsage
      expr: (pve_disk_usage_bytes{id=~"storage/.*"} / pve_disk_size_bytes) * 100 > 95
      for: 30m
      labels:
        severity: warning
      annotations:
        summary: "Alto uso de disco no host Proxmox"
        description: "O storage {{ $labels.id }} no host Proxmox {{ $labels.instance }} está com uso acima de 80% ({{ $value | humanizePercentage }}) nos últimos 30 minutos."
        dashboard_url: "https://grafana.felipecisotto.com.br/d/Dp7Cd57Zza/proxmox-overview?orgId=1&refresh=10s"

    # Alerta para uso crítico de disco no host Proxmox
    - alert: ProxmoxHostCriticalDiskUsage
      expr: (pve_disk_usage_bytes{id=~"storage/.*"} / pve_disk_size_bytes) * 100 > 99
      for: 15m
      labels:
        severity: critical
      annotations:
        summary: "Uso crítico de disco no host Proxmox"
        description: "O storage {{ $labels.id }} no host Proxmox {{ $labels.instance }} está com uso acima de 95% ({{ $value | humanizePercentage }}) nos últimos 15 minutos."
        dashboard_url: "https://grafana.felipecisotto.com.br/d/Dp7Cd57Zza/proxmox-overview?orgId=1&refresh=10s"

  - name: proxmox.vm.rules
    rules:
    # Alerta para uso elevado de CPU em VM do Proxmox
    - alert: ProxmoxVMHighCPUUsage
      expr: ((pve_cpu_usage_ratio * on(id, instance) group_left(name, type) pve_guest_info) / (pve_cpu_usage_limit * on(id, instance) group_left(name, type) pve_guest_info)) * 100 > 90
      for: 10m
      labels:
        severity: warning
      annotations:
        summary: "Alto uso de CPU em VM do Proxmox"
        description: "A VM '{{ $labels.name }}' ({{ $labels.type }}) no host Proxmox {{ $labels.instance }} está com uso de CPU acima de 90% ({{ $value | humanizePercentage }}) nos últimos 10 minutos."
        dashboard_url: "https://grafana.felipecisotto.com.br/d/Dp7Cd57Zza/proxmox-overview?orgId=1&refresh=10s"

    # Alerta para uso elevado de memória em VM do Proxmox
    - alert: ProxmoxVMHighMemoryUsage
      expr: ((pve_memory_usage_bytes * on(id, instance) group_left(name, type) pve_guest_info) / (pve_memory_size_bytes * on(id, instance) group_left(name, type) pve_guest_info)) * 100 > 95
      for: 10m
      labels:
        severity: warning
      annotations:
        summary: "Alto uso de memória em VM do Proxmox"
        description: "A VM '{{ $labels.name }}' ({{ $labels.type }}) no host Proxmox {{ $labels.instance }} está com uso de memória acima de 95% ({{ $value | humanizePercentage }}) nos últimos 10 minutos."
        dashboard_url: "https://grafana.felipecisotto.com.br/d/Dp7Cd57Zza/proxmox-overview?orgId=1&refresh=10s"

    # Alerta para uso elevado de disco em VM do Proxmox
    - alert: ProxmoxVMHighDiskUsage
      expr: ((pve_disk_usage_bytes * on(id, instance) group_left(name, type) pve_guest_info{type="lxc"}) / (pve_disk_size_bytes * on(id, instance) group_left(name, type) pve_guest_info{type="lxc"})) * 100 > 90
      for: 30m
      labels:
        severity: warning
      annotations:
        summary: "Alto uso de disco em LXC do Proxmox"
        description: "A VM '{{ $labels.name }}' ({{ $labels.type }}) no host Proxmox {{ $labels.instance }} está com uso de disco acima de 90% ({{ $value | humanizePercentage }}) nos últimos 30 minutos."
        dashboard_url: "https://grafana.felipecisotto.com.br/d/Dp7Cd57Zza/proxmox-overview?orgId=1&refresh=10s"

---
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: kubernetes-alerts
  namespace: monitoring
  labels:
    app.kubernetes.io/name: prometheus-operator
    app.kubernetes.io/part-of: kube-prometheus
spec:
  groups:
  - name: kubernetes.pods.rules
    rules:
    # Alerta para pods com muitos restarts
    - alert: KubernetesPodRestartingTooMuch
      expr: increase(kube_pod_container_status_restarts_total[1h]) > 5
      for: 10m
      labels:
        severity: warning
      annotations:
        summary: "Pod reiniciando frequentemente"
        description: "O pod {{ $labels.pod }} no namespace {{ $labels.namespace }} reiniciou {{ $value }} vezes na última hora."
        dashboard_url: "https://grafana.felipecisotto.com.br/d/kubernetes-cluster/kubernetes-cluster-monitoring-via-prometheus?orgId=1"

    # Alerta para pods em estado unhealthy por muito tempo
    - alert: KubernetesPodNotHealthy
      expr: sum by(namespace, pod) (kube_pod_status_phase{phase=~"Failed|Pending|Unknown"}) > 0
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: "Pod não está saudável"
        description: "O pod {{ $labels.pod }} no namespace {{ $labels.namespace }} está em estado não saudável (Failed, Pending ou Unknown) por mais de 5 minutos."
        dashboard_url: "https://grafana.felipecisotto.com.br/d/kubernetes-cluster/kubernetes-cluster-monitoring-via-prometheus?orgId=1"

    # Alerta para containeres que não iniciam corretamente
    - alert: KubernetesContainerWaiting
      expr: sum by(namespace, pod, container) (kube_pod_container_status_waiting_reason{reason!=""}) > 0
      for: 1h
      labels:
        severity: warning
      annotations:
        summary: "Container em estado waiting por muito tempo"
        description: "O container {{ $labels.container }} no pod {{ $labels.pod }} (namespace {{ $labels.namespace }}) está em estado waiting há mais de 1 hora."
        dashboard_url: "https://grafana.felipecisotto.com.br/d/kubernetes-cluster/kubernetes-cluster-monitoring-via-prometheus?orgId=1"

  - name: kubernetes.resource.rules
    rules:
    # Alerta para nós com pouco espaço em disco
    - alert: KubernetesNodeDiskPressure
      expr: 100 - ((node_filesystem_avail_bytes{mountpoint="/"} * 100) / node_filesystem_size_bytes{mountpoint="/"}) > 85
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: "Nó com pouco espaço em disco"
        description: "O nó {{ $labels.instance }} está com utilização de disco acima de 85% ({{ $value | humanizePercentage }}) nos últimos 5 minutos."
        dashboard_url: "https://grafana.felipecisotto.com.br/d/kubernetes-cluster/kubernetes-cluster-monitoring-via-prometheus?orgId=1"

  - name: kubernetes.system.rules
    rules:
    # Alerta para namespaces com muitos pods em estado failed ou pending
    - alert: KubernetesNamespaceManyFailedPods
      expr: sum by(namespace) (kube_pod_status_phase{phase=~"Failed|Pending"}) > 5
      for: 10m
      labels:
        severity: warning
      annotations:
        summary: "Muitos pods com falha em um namespace"
        description: "O namespace {{ $labels.namespace }} possui {{ $value }} pods em estado Failed ou Pending por mais de 10 minutos."
        dashboard_url: "https://grafana.felipecisotto.com.br/d/kubernetes-cluster/kubernetes-cluster-monitoring-via-prometheus?orgId=1"

    # Alerta para PVCs pendentes
    - alert: KubernetesPersistentVolumeClaimPending
      expr: kube_persistentvolumeclaim_status_phase{phase="Pending"} == 1
      for: 1h
      labels:
        severity: warning
      annotations:
        summary: "PVC pendente por muito tempo"
        description: "O PVC {{ $labels.persistentvolumeclaim }} no namespace {{ $labels.namespace }} está pendente há mais de 1 hora."
        dashboard_url: "https://grafana.felipecisotto.com.br/d/kubernetes-cluster/kubernetes-cluster-monitoring-via-prometheus?orgId=1"

    # Alerta para problemas no etcd
    - alert: KubernetesEtcdHighNumberOfLeaderChanges
      expr: increase(etcd_server_leader_changes_seen_total[1h]) > 3
      for: 10m
      labels:
        severity: critical
      annotations:
        summary: "Alta taxa de mudanças de líder no etcd"
        description: "Etcd viu {{ $value }} mudanças de líder na última hora - isso pode indicar instabilidade no cluster."
        dashboard_url: "https://grafana.felipecisotto.com.br/d/kubernetes-cluster/kubernetes-cluster-monitoring-via-prometheus?orgId=1"

    # Alerta para deployment incompleto
    - alert: KubernetesDeploymentReplicasMismatch
      expr: kube_deployment_spec_replicas != kube_deployment_status_replicas_available
      for: 15m
      labels:
        severity: warning
      annotations:
        summary: "Deployment com réplicas indisponíveis"
        description: "O deployment {{ $labels.deployment }} no namespace {{ $labels.namespace }} não conseguiu provisionar todas as réplicas desejadas por mais de 15 minutos."
        dashboard_url: "https://grafana.felipecisotto.com.br/d/kubernetes-cluster/kubernetes-cluster-monitoring-via-prometheus?orgId=1"
